{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"./zhengqi_train.txt\"\n",
    "test_data_file = \"./zhengqi_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_file, sep=\"\\t\", encoding='utf-8')\n",
    "test_data = pd.read_csv(test_data_file, sep='\\t', encoding='utf-8')\n",
    "train_data.info() # 数据的行列信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.describe(); # 数据的统计信息：均值、方差、4分位值等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,6))\n",
    "sns.boxplot(train_data['V0'], orient=\"v\", width=0.5) #绘制箱线图\n",
    "\n",
    "# column = train_data.columns.tolist()[:39]\n",
    "# fig = plt.figure(figsize=(80,60), dpi=75)\n",
    "# for i in range(38):\n",
    "#     plt.subplot(7,8,i+1)\n",
    "#     sns.boxplot(train_data[column[i]], orient='v', width=0.5)\n",
    "#     plt.ylabel(column[i], fontsize=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(model, X, y, sigma=3):\n",
    "    \"\"\"\n",
    "    找出异常值\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 生成预测值\n",
    "        y_pred = pd.Series(model.predict(X), index=y.index)\n",
    "    except:\n",
    "        model.fit(X, y)\n",
    "        y_pred = pd.Series(model.predict(X), index=y.index)\n",
    "        \n",
    "    # 误差    \n",
    "    resid = y - y_pred\n",
    "    # 误差均值\n",
    "    mean_resid = resid.mean()\n",
    "    # 误差的标准差\n",
    "    std_resid = resid.std()\n",
    "    \n",
    "    z = (resid - mean_resid)/std_resid\n",
    "    \n",
    "    #找出边界点\n",
    "    outliers = z[abs(z)>sigma].index\n",
    "    \n",
    "    print('R2=',model.score(X, y))\n",
    "    \n",
    "    # 均方差\n",
    "    print(\"mse\", mean_squared_error(y,y_pred))\n",
    "    print('--------------------------------------------')\n",
    "    \n",
    "    print('mean of residuals:', mean_resid)\n",
    "    print('std of residuals:', std_resid)\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    print(len(outliers),'outliers:')\n",
    "    print(outliers.tolist())\n",
    "    \n",
    "    #y,y_pred\n",
    "    plt.figure(figsize=(15,5))\n",
    "    ax_131 = plt.subplot(1,3,1)\n",
    "    plt.plot(y,y_pred, '.') #异常\n",
    "    plt.plot(y.loc[outliers], y_pred.loc[outliers], 'ro') #不接受\n",
    "    plt.legend(['Accepted','Outlier'])\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y_pred')\n",
    "    \n",
    "    #y,y-pred\n",
    "    ax_132 = plt.subplot(1,3,2)\n",
    "    plt.plot(y,y-y_pred, '.') #异常\n",
    "    plt.plot(y.loc[outliers], y.loc[outliers]-y_pred.loc[outliers],'ro')  #不接受\n",
    "    plt.legend(['Accepted','Outlier'])\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y - y_read')\n",
    "    \n",
    "    #值\n",
    "    ax_133 = plt.subplot(1,3,3)\n",
    "    z.plot.hist(bins=50, ax=ax_133) #异常\n",
    "    z.loc[outliers].plot.hist(color='r', bins=50, ax=ax_133)  #不接受\n",
    "    plt.legend(['Accepted', 'Outlier'])\n",
    "    plt.xlabel('z')\n",
    "    \n",
    "    plt.savefig('outliers.png')\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X_train = train_data.iloc[:,0:-1]\n",
    "y_train = train_data.iloc[:,-1]\n",
    "# STEP1 采用**模型预测的模式**找出异常值 \n",
    "# -> 其思想是，采用一个标准模型对训练集数据进行预测，然后排除\n",
    "# 掉偏离训练数据（y）过多的数据\n",
    "outliers = find_outliers(Ridge(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP2 统计假设校验\n",
    "\n",
    "# 统计方法一般都有其适用的条件，或者说是必须满足的。\n",
    "# 使用线性回归需要满足线性、独立性、正态性、方差齐性、自变量间不存在多重共线、因变量为连续变量。\n",
    "# 不考虑前提条件地生搬硬套，也不对模型进行诊断，只能是“Garbage in，garbage out”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[线性回归中的正态分布](https://mp.weixin.qq.com/s?__biz=MzIzNjk2NDg4NA==&mid=2247484629&idx=1&sn=b542cc03895de8aea58f63f574159f60&chksm=e8ce99aedfb910b8861cdb0b161c0c18d12a196921e8c5fd808334afdef6fa16756d80649aa2&token=2074505415&lang=zh_CN#rd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设1: 正态性校验\n",
    "\n",
    "# 直方图和Q-Q图\n",
    "# 指数据的分位数和正态分布分为数对比参照的图，如果数据符合正态分布，则所有的点都会落在直线上\n",
    "# 查看V0是否近似正态分布\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "sns.distplot(train_data['V0'], fit=stats.norm)\n",
    "ax=plt.subplot(1,2,2)\n",
    "res = stats.probplot(train_data['V0'], plot=plt)\n",
    "train_cols = 6\n",
    "train_rows = len(train_data.columns)\n",
    "plt.figure(figsize=(4*train_cols, 4*train_rows))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for col in train_data.columns:\n",
    "    i+=1\n",
    "    ax = plt.subplot(train_rows, train_cols, i)\n",
    "    sns.distplot(train_data[col],fit=stats.norm)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    ax=plt.subplot(train_rows, train_cols, i)\n",
    "    res = stats.probplot(train_data[col], plot=plt)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ...数据分布不是正态的，数据并不跟随对角线分布，后续可以使用数据变换对这些数据进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设2: 训练数据和测试数据同分布校验\n",
    "# KDE分布图 核密度估计\n",
    "# 可以理解为是对直方图对加窗平滑。通过绘制KDE分布图，可以查看并对比训练集和测试集中特征变量对分布情况，\n",
    "# 发现两个数据集中分布不一致的特征变量\n",
    "\n",
    "# 首先对比同一特征变量V0在训练集和测试集中的分布情况，并查看数据分布是否一致。\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=150)\n",
    "ax = sns.kdeplot(train_data['V0'], color=\"Red\", shade=True)\n",
    "ax = sns.kdeplot(test_data['V0'], color=\"Blue\",shade=True)\n",
    "ax.set_xlabel('V0')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax = ax.legend([\"train\",\"test\"])\n",
    "\n",
    "# 可以看到V0在两个数据集中的分布基本一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后对比所有变量在训练集和测试集中的KDE分布\n",
    "\n",
    "dist_cols = 6\n",
    "dist_rows = len(test_data.columns)\n",
    "plt.figure(figsize=(4 * dist_cols, 4 * dist_rows))\n",
    "i = 1\n",
    "for col in test_data.columns:\n",
    "    ax = plt.subplot(dist_rows, dist_cols, i)\n",
    "    ax = sns.kdeplot(train_data[col], color=\"Red\", shade=True)\n",
    "    ax = sns.kdeplot(test_data[col], color=\"Blue\", shade=True)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax = ax.legend([\"train\",\"test\"])\n",
    "    i += 1\n",
    "plt.show()    \n",
    "\n",
    "# 可以看到变量A。。。在训练集和测试集中的分布不一致，这会导致模型的**泛化能力**变差，需要删除此类特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#假设3: 分析变量之间的线性回归关系\n",
    "# 线性回归关系图\n",
    "# 分析变量之间的线性回归关系。\n",
    "\n",
    "\n",
    "# 首先查看*特征变量*V0与*target*变量的线性回归关系\n",
    "\n",
    "\n",
    "\n",
    "fcols = 2\n",
    "frows = 1\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=150)\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "sns.regplot(x='V0', y='target', data=train_data, ax=ax,\n",
    "           scatter_kws={'marker':'.','s':3,'alpha':0.3}, line_kws={'color':'k'})\n",
    "plt.xlabel('V0')\n",
    "plt.ylabel('target')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "sns.distplot(train_data['V0'].dropna())\n",
    "plt.xlabel('V0')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcols = 6\n",
    "frows = len(test_data.columns)\n",
    "plt.figure(figsize=(5*fcols, 4*frows))\n",
    "\n",
    "i = 0\n",
    "for col in test_data.columns:\n",
    "    i += 1\n",
    "    ax = plt.subplot(frows, fcols, i)\n",
    "    sns.regplot(x = col, y='target', data=train_data, ax=ax,\n",
    "               scatter_kws={'marker':'.', 's':3, 'alpha':0.3}, line_kws={'color':'k'});\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('target')\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    ax = plt.subplot(frows, fcols, i)\n",
    "    sns.distplot(train_data[col].dropna())\n",
    "    plt.xlabel(col)\n",
    "    \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[线性回归中的正态分布](https://mp.weixin.qq.com/s?__biz=MzIzNjk2NDg4NA==&mid=2247484629&idx=1&sn=b542cc03895de8aea58f63f574159f60&chksm=e8ce99aedfb910b8861cdb0b161c0c18d12a196921e8c5fd808334afdef6fa16756d80649aa2&token=2074505415&lang=zh_CN#rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows',10)\n",
    "\n",
    "# 删除训练集和测试集中**分布不一致**的特征变量\n",
    "data_train1 = train_data.drop([\n",
    "    'V5','V9','V11','V17','V22','V28'\n",
    "], axis=1)\n",
    "\n",
    "train_corr = data_train1.corr()\n",
    "\n",
    "# 计算**剩余**特征变量及target变量的相关性系数\n",
    "\n",
    "ax = plt.subplots(figsize=(20,16))\n",
    "ax = sns.heatmap(train_corr, vmax=.8, square=True, annot=True)\n",
    "annot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据相关系数筛选特征变量\n",
    "\n",
    "k = 10 # number of variables for heatmap\n",
    "cols = train_corr.nlargest(k, 'target')['target'].index\n",
    "\n",
    "cm = np.corrcoef(train_data[cols].values.T)\n",
    "hm = plt.subplots(figsize=(10,10))\n",
    "hm = sns.heatmap(train_data[cols].corr(), annot=True, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后找出与target变量的相关系数大于0.5的特征变量\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "corrmat = train_data.corr()\n",
    "top_corr_features = corrmat.index[abs(corrmat[\"target\"])>threshold]\n",
    "plt.figure(figsize=(10,10))\n",
    "g = sns.heatmap(train_data[top_corr_features].corr(), annot=True, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "corr_matrix = data_train1.corr().abs() # 取相关性绝对值\n",
    "drop_col = corr_matrix[corr_matrix[\"target\"]<threshold].index\n",
    "# data_all.drop(drop_col, axis=1, inplace=True) # 删除不重要的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Cox变换\n",
    "# 由于线性回归是基于正态分布的，因此在进行统计分析时，需要将数据转换使其符合正态分布\n",
    "\n",
    "\n",
    "# 在连续的响应变量不满足正态分布时，可以使用Box-Cox变换，这一变换可以使线性回归模型在满足线性、正态性、独立性及方差齐性\n",
    "# 的同时又不丢失信息\n",
    "\n",
    "\n",
    "drop_columns = ['V5','V9','V11','V17','V22','V28']\n",
    "\n",
    "train_x = train_data.drop(['target'], axis=1)\n",
    "\n",
    "data_all = pd.concat([train_x, test_data])\n",
    "\n",
    "data_all.drop(drop_columns, axis=1, inplace=True)\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对合并后的每列数据进行归一化：\n",
    "\n",
    "cols_numeric = list(data_all.columns)\n",
    "\n",
    "def scale_minmax(col):\n",
    "    return (col - col.min())/(col.max() - col.min())\n",
    "\n",
    "data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis=0)\n",
    "data_all[cols_numeric].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_process = train_data[cols_numeric]\n",
    "train_data_process =  train_data_process[cols_numeric].apply(scale_minmax,axis=0)\n",
    "\n",
    "test_data_process = train_data[cols_numeric]\n",
    "test_data_process = test_data_process[cols_numeric].apply(scale_minmax, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_numeric_left = cols_numeric[0:13]\n",
    "cols_numeric_right = cols_numeric[13:]\n",
    "train_data_process = pd.concat([train_data_process, train_data['target']], axis=1)\n",
    "\n",
    "\n",
    "fcols = 6\n",
    "frows = len(cols_numeric_left)\n",
    "plt.figure(figsize=(4 * fcols, 4*frows))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for var in cols_numeric_left:\n",
    "    dat = train_data_process[[var,'target']].dropna()\n",
    "    i += 1\n",
    "    plt.subplot(frows, fcols, i)\n",
    "    sns.distplot(dat[var], fit=stats.norm)\n",
    "    plt.title(var + ' Original')\n",
    "    plt.xlabel('')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(frows, fcols, i)\n",
    "    _ =  stats.probplot(dat[var], plot=plt)\n",
    "    plt.title('skew='+'{:.4f}'.format(stats.skew(dat[var])))\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(frows, fcols,i)\n",
    "    plt.plot(dat[var], dat['target'], '.', alpha=0.5)\n",
    "    try:\n",
    "        plt.title('corr='+ '{:.2f}'.format(np.corrcoef(dat[var],dat['target'])[0][1]))\n",
    "    except Exception  as e:\n",
    "        print(\"error {}\".format(e))\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(frows, fcols, i)\n",
    "    #boxcox 变换\n",
    "    trans_var, lambda_var = stats.boxcox(dat[var].dropna()+1)\n",
    "    trans_var = scale_minmax(trans_var)\n",
    "    sns.distplot(trans_var, fit=stats.norm)\n",
    "    plt.title(var + ' Transformed')\n",
    "    plt.xlabel('')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(frows, fcols, i)\n",
    "    _ = stats.probplot(trans_var, plot=plt)\n",
    "    plt.title('skew='+'{:.4f}'.format(stats.skew(trans_var)))\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    \n",
    "    i+=1\n",
    "    plt.subplot(frows, fcols, i)\n",
    "    plt.plot(trans_var, dat['target'], '.', alpha=0.5)\n",
    "    try:\n",
    "        plt.title('corr='+ '{:.2f}'.format(np.corrcoef(trans_var,dat['target'])[0][1]))\n",
    "    except Exception as e:\n",
    "        print(\"error {}\".format(e))\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
